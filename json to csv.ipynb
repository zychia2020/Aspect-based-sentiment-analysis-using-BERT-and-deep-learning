{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "837f4412-5d69-4fb6-8426-b94805893a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2967\n",
      "2092\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "file_path = 'MEMD_ABSA_Dataset/Books/'\n",
    "\n",
    "# Read the JSON file into a Pandas DataFrame\n",
    "df = pd.read_json(file_path + 'Dev.json')\n",
    "df1 = pd.read_json(file_path + 'Test.json')\n",
    "df2 = pd.read_json(file_path + 'Train.json')\n",
    "\n",
    "merged_df = pd.concat([df, df1,df2], axis=0, ignore_index=True)\n",
    "print(len(merged_df))\n",
    "print(len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afdd7a2f-9a92-4619-9a17-c29e9fa28a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    {'aspect': {'from': 1, 'to': 2, 'term': ['book...\n",
       "3    {'aspect': {'from': 14, 'to': 16, 'term': ['ne...\n",
       "Name: quadruples, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_exploded = df.explode('quadruples')\n",
    "display(df_exploded['quadruples'][3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "258c82b1-9c26-42d3-b07e-3039f3b24320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>aspect</th>\n",
       "      <th>opinion</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unfortunately , it was n't up to par with her ...</td>\n",
       "      <td>[[NULL]]</td>\n",
       "      <td>[[Unfortunately], [Unfortunately]]</td>\n",
       "      <td>[NEG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not only was the whole plane crash into a very...</td>\n",
       "      <td>[[NULL]]</td>\n",
       "      <td>[[bad], [bad]]</td>\n",
       "      <td>[NEG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A very good read from the author who saw it al...</td>\n",
       "      <td>[[read]]</td>\n",
       "      <td>[[very, good], [very, good]]</td>\n",
       "      <td>[POS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This book was worth the wait , and I will keep...</td>\n",
       "      <td>[[book], [next, novel]]</td>\n",
       "      <td>[[worth], [worth], [NULL], [NULL]]</td>\n",
       "      <td>[POS, POS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An excellent page turner .</td>\n",
       "      <td>[[page, turner]]</td>\n",
       "      <td>[[excellent], [excellent]]</td>\n",
       "      <td>[POS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>Excellent and in-depth of the exquisitely comp...</td>\n",
       "      <td>[[NULL], [NULL]]</td>\n",
       "      <td>[[Excellent], [Excellent], [in-depth], [in-dep...</td>\n",
       "      <td>[POS, POS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963</th>\n",
       "      <td>Add to it a lot of local color of modern urban...</td>\n",
       "      <td>[[NULL]]</td>\n",
       "      <td>[[good], [good]]</td>\n",
       "      <td>[POS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2964</th>\n",
       "      <td>It is also a story of paternalism , arrogance ...</td>\n",
       "      <td>[[story]]</td>\n",
       "      <td>[[NULL], [NULL]]</td>\n",
       "      <td>[NEG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2965</th>\n",
       "      <td>Another great story with a twist .</td>\n",
       "      <td>[[story]]</td>\n",
       "      <td>[[great], [great]]</td>\n",
       "      <td>[POS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2966</th>\n",
       "      <td>Writing was very stilted , boring and unsophis...</td>\n",
       "      <td>[[Writing], [Writing], [Writing]]</td>\n",
       "      <td>[[unsophisticated], [unsophisticated], [very, ...</td>\n",
       "      <td>[NEG, NEG, NEG]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2967 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  \\\n",
       "0     Unfortunately , it was n't up to par with her ...   \n",
       "1     Not only was the whole plane crash into a very...   \n",
       "2     A very good read from the author who saw it al...   \n",
       "3     This book was worth the wait , and I will keep...   \n",
       "4                            An excellent page turner .   \n",
       "...                                                 ...   \n",
       "2962  Excellent and in-depth of the exquisitely comp...   \n",
       "2963  Add to it a lot of local color of modern urban...   \n",
       "2964  It is also a story of paternalism , arrogance ...   \n",
       "2965                 Another great story with a twist .   \n",
       "2966  Writing was very stilted , boring and unsophis...   \n",
       "\n",
       "                                 aspect  \\\n",
       "0                              [[NULL]]   \n",
       "1                              [[NULL]]   \n",
       "2                              [[read]]   \n",
       "3               [[book], [next, novel]]   \n",
       "4                      [[page, turner]]   \n",
       "...                                 ...   \n",
       "2962                   [[NULL], [NULL]]   \n",
       "2963                           [[NULL]]   \n",
       "2964                          [[story]]   \n",
       "2965                          [[story]]   \n",
       "2966  [[Writing], [Writing], [Writing]]   \n",
       "\n",
       "                                                opinion        sentiment  \n",
       "0                    [[Unfortunately], [Unfortunately]]            [NEG]  \n",
       "1                                        [[bad], [bad]]            [NEG]  \n",
       "2                          [[very, good], [very, good]]            [POS]  \n",
       "3                    [[worth], [worth], [NULL], [NULL]]       [POS, POS]  \n",
       "4                            [[excellent], [excellent]]            [POS]  \n",
       "...                                                 ...              ...  \n",
       "2962  [[Excellent], [Excellent], [in-depth], [in-dep...       [POS, POS]  \n",
       "2963                                   [[good], [good]]            [POS]  \n",
       "2964                                   [[NULL], [NULL]]            [NEG]  \n",
       "2965                                 [[great], [great]]            [POS]  \n",
       "2966  [[unsophisticated], [unsophisticated], [very, ...  [NEG, NEG, NEG]  \n",
       "\n",
       "[2967 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def extract_attributes(quadruples):\n",
    "    aspects = []\n",
    "    opinions = []\n",
    "    sentiments = []\n",
    "\n",
    "    for quad in quadruples:\n",
    "        aspect = quad.get('aspect', {}).get('term', None)\n",
    "        opinion = quad.get('opinion', {}).get('term', None)\n",
    "        sentiment = quad.get('sentiment', {})\n",
    "\n",
    "\n",
    "        aspects.append(aspect)\n",
    "        opinions.append(opinion)\n",
    "        opinions.append(opinion)\n",
    "        sentiments.append(sentiment)\n",
    "        \n",
    "    return aspects, opinions, sentiments\n",
    "\n",
    "# Apply the function to each row of the DataFrame\n",
    "merged_df[['aspect', 'opinion', 'sentiment']] = merged_df['quadruples'].apply(lambda x: pd.Series(extract_attributes(x)))\n",
    "# df1[['aspect', 'opinion']] = df1['quadruples'].apply(lambda x: pd.Series(extract_attributes(x)))\n",
    "# df2[['aspect', 'opinion']] = df2['quadruples'].apply(lambda x: pd.Series(extract_attributes(x)))\n",
    "\n",
    "# Now you have 'aspects' and 'opinions' columns containing lists of aspect and opinion terms for each row\n",
    "# Assuming df is your DataFrame\n",
    "# df.rename(columns={'raw_words': 'sentence'}, inplace=True)\n",
    "merged_df = merged_df.rename(columns={'raw_words': 'sentence'})\n",
    "# df1 = df1.rename(columns={'raw_words': 'sentence'})\n",
    "# df2 = df2.rename(columns={'raw_words': 'sentence'})\n",
    "subset_df = merged_df.loc[0:, ['sentence', 'aspect', 'opinion','sentiment']]\n",
    "display(subset_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d964656c-25fa-4735-900b-0bcab3dcea7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m sentiments \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Create a DataFrame for the current row's aspect-opinion pairs\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m row_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m: [sentence] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(aspects),\n\u001b[0;32m     38\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maspect\u001b[39m\u001b[38;5;124m'\u001b[39m: aspects,\n\u001b[0;32m     39\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopinion\u001b[39m\u001b[38;5;124m'\u001b[39m: opinions,\n\u001b[0;32m     40\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m : sentiments})\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Append the DataFrame to the list\u001b[39;00m\n\u001b[0;32m     43\u001b[0m dfs\u001b[38;5;241m.\u001b[39mappend(row_df)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\FYP\\Lib\\site-packages\\pandas\\core\\frame.py:767\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    761\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    762\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    763\u001b[0m     )\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 767\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\FYP\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\FYP\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\FYP\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df contains your DataFrame\n",
    "\n",
    "# Create an empty list to store DataFrames for each row\n",
    "def expand_sentences(datasets):\n",
    "    new_datasets = []\n",
    "\n",
    "    # Iterate through each row of the original DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        sentence = row['sentence']\n",
    "        aspects = row['aspect']\n",
    "        opinions = row['opinion']\n",
    "        sentiments = row['sentiment']\n",
    "        \n",
    "        # Create a DataFrame for the current row's aspect-opinion pairs\n",
    "        row_df = pd.DataFrame({'sentence': [sentence] * len(aspects),\n",
    "                               'aspect': aspects,\n",
    "                               'opinion': opinions,\n",
    "                              'sentiment' : sentiments})\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        new_datasets.append(row_df)\n",
    "\n",
    "    return new_datasets\n",
    "\n",
    "dfs = []\n",
    "\n",
    "# Iterate through each row of the original DataFrame\n",
    "for index, row in merged_df.iterrows():\n",
    "    sentence = row['sentence']\n",
    "    aspects = row['aspect']\n",
    "    opinions = row['opinion']\n",
    "    sentiments = row['sentiment']\n",
    "    \n",
    "    # Create a DataFrame for the current row's aspect-opinion pairs\n",
    "    row_df = pd.DataFrame({'sentence': [sentence] * len(aspects),\n",
    "                           'aspect': aspects,\n",
    "                           'opinion': opinions,\n",
    "                          'sentiment' : sentiments})\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    dfs.append(row_df)\n",
    "\n",
    "# Concatenate all DataFrames in the list to create the expanded DataFrame\n",
    "\n",
    "expanded_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "expanded_df = expanded_df.loc[0:, ['sentence', 'aspect', 'opinion', 'sentiment']]\n",
    "display(expanded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d435fea2-91f0-4204-bddd-d6c4c0a19619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df contains your DataFrame\n",
    "\n",
    "# Create an empty list to store DataFrames for each row\n",
    "dfs1 = []\n",
    "\n",
    "# Iterate through each row of the original DataFrame\n",
    "for index, row in df1.iterrows():\n",
    "    raw_words1 = row['raw_words']\n",
    "    aspects1 = row['aspect']\n",
    "    opinions1 = row['opinion']\n",
    "\n",
    "    \n",
    "    # Create a DataFrame for the current row's aspect-opinion pairs\n",
    "    row_df1 = pd.DataFrame({'raw_words': [raw_words1] * len(aspects1),\n",
    "                           'aspect': aspects1,\n",
    "                           'opinion': opinions1})\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    dfs1.append(row_df1)\n",
    "\n",
    "# Concatenate all DataFrames in the list to create the expanded DataFrame\n",
    "expanded_df1 = pd.concat(dfs1, ignore_index=True)\n",
    "\n",
    "# Print the expanded DataFrame\n",
    "display(expanded_df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e52d94e2-2748-4090-85ad-abf88509bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df contains your DataFrame\n",
    "\n",
    "# Create an empty list to store DataFrames for each row\n",
    "dfs2 = []\n",
    "\n",
    "# Iterate through each row of the original DataFrame\n",
    "for index, row in df2.iterrows():\n",
    "    raw_words2 = row['raw_words']\n",
    "    aspects2 = row['aspect']\n",
    "    opinions2 = row['opinion']\n",
    "    \n",
    "    # Create a DataFrame for the current row's aspect-opinion pairs\n",
    "    row_df2 = pd.DataFrame({'raw_words': [raw_words2] * len(aspects2),\n",
    "                           'aspect': aspects2,\n",
    "                           'opinion': opinions2})\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    dfs2.append(row_df2)\n",
    "\n",
    "# Concatenate all DataFrames in the list to create the expanded DataFrame\n",
    "expanded_df2 = pd.concat(dfs2, ignore_index=True)\n",
    "\n",
    "# Print the expanded DataFrame\n",
    "display(expanded_df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57c9cd5c-6fcd-479b-a188-748cfd64329a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>aspect</th>\n",
       "      <th>opinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FINALLY got around to trying this place since ...</td>\n",
       "      <td>place</td>\n",
       "      <td>well worth it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The hostess looked at us confused , because ou...</td>\n",
       "      <td>hostess</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finally we order , and then wait , and wait , ...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>They brought us out some complimentary hummus ...</td>\n",
       "      <td>complimentary hummus</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I love their baked beans - they 're rich and f...</td>\n",
       "      <td>baked beans</td>\n",
       "      <td>rich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>Definitely not worth it and will likely never ...</td>\n",
       "      <td>place</td>\n",
       "      <td>Definitely not worth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>After initial orders for beverages , our waitr...</td>\n",
       "      <td>waitress</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>We had a pretty big table and everyone seemed ...</td>\n",
       "      <td>food</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>We had a pretty big table and everyone seemed ...</td>\n",
       "      <td>table</td>\n",
       "      <td>pretty big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>I ordered a side of dipper fries as well , but...</td>\n",
       "      <td>dipper fries</td>\n",
       "      <td>gross</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>803 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence                aspect  \\\n",
       "2    FINALLY got around to trying this place since ...                 place   \n",
       "3    The hostess looked at us confused , because ou...               hostess   \n",
       "4    Finally we order , and then wait , and wait , ...                  NULL   \n",
       "5    They brought us out some complimentary hummus ...  complimentary hummus   \n",
       "6    I love their baked beans - they 're rich and f...           baked beans   \n",
       "..                                                 ...                   ...   \n",
       "800  Definitely not worth it and will likely never ...                 place   \n",
       "801  After initial orders for beverages , our waitr...              waitress   \n",
       "802  We had a pretty big table and everyone seemed ...                  food   \n",
       "803  We had a pretty big table and everyone seemed ...                 table   \n",
       "804  I ordered a side of dipper fries as well , but...          dipper fries   \n",
       "\n",
       "                  opinion  \n",
       "2           well worth it  \n",
       "3                    NULL  \n",
       "4                    NULL  \n",
       "5                    NULL  \n",
       "6                    rich  \n",
       "..                    ...  \n",
       "800  Definitely not worth  \n",
       "801                  NULL  \n",
       "802                  love  \n",
       "803            pretty big  \n",
       "804                 gross  \n",
       "\n",
       "[803 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def remove_Bracket(dataset):\n",
    "    dataset['aspect'] = dataset['aspect'].apply(lambda x: ' '.join(map(str, x))).str.strip('[]')\n",
    "    dataset['opinion'] = dataset['opinion'].apply(lambda x: ' '.join(map(str, x))).str.strip('[]')\n",
    "\n",
    "\n",
    "# Remove square brackets from 'aspect' and 'opinion' columns\n",
    "expanded_df['aspect'] = expanded_df['aspect'].apply(lambda x: ' '.join(map(str, x))).str.strip('[]')\n",
    "expanded_df['opinion'] = expanded_df['opinion'].apply(lambda x: ' '.join(map(str, x))).str.strip('[]')\n",
    "\n",
    "expanded_df1['aspect'] = expanded_df1['aspect'].apply(lambda x: ' '.join(map(str, x))).str.strip('[]')\n",
    "expanded_df1['opinion'] = expanded_df1['opinion'].apply(lambda x: ' '.join(map(str, x))).str.strip('[]')\n",
    "\n",
    "expanded_df2['aspect'] = expanded_df2['aspect'].apply(lambda x: ' '.join(map(str, x))).str.strip('[]')\n",
    "expanded_df2['opinion'] = expanded_df2['opinion'].apply(lambda x: ' '.join(map(str, x))).str.strip('[]')\n",
    "\n",
    "# Print the DataFrame with square brackets removed\n",
    "\n",
    "expanded_df = expanded_df.loc[0:, ['sentence', 'aspect', 'opinion']]\n",
    "display(expanded_df)\n",
    "display(expanded_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "128dd919-6907-49b1-9366-c32c664b169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expanded_df.to_csv('dev.csv', index=False)\n",
    "# expanded_df1.to_csv('test.csv', index=False)\n",
    "# expanded_df2.to_csv('train.csv', index=False)\n",
    "\n",
    "merged_df = pd.concat(expanded_df,expanded_df1,expanded_df2], axis=0, ignore_index=True)\n",
    "merged_df.to_csv('Books.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb97d8ba-e232-4da3-b485-4de09cd78848",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'expanded_df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# df1 = pd.read_csv('dev.csv')\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# df2 = pd.read_csv('test.csv')\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# df3 = pd.read_csv('train.csv')\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([expanded_df, expanded_df1,expanded_df2], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(merged_df))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'expanded_df1' is not defined"
     ]
    }
   ],
   "source": [
    "# df1 = pd.read_csv('dev.csv')\n",
    "# df2 = pd.read_csv('test.csv')\n",
    "# df3 = pd.read_csv('train.csv')\n",
    "\n",
    "\n",
    "# merged_df = pd.concat([expanded_df, expanded_df1,expanded_df2], axis=0, ignore_index=True)\n",
    "# print(len(merged_df))\n",
    "# merged_df.to_csv('memd_laptop.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175dae06-eacb-45ed-a930-4b5e8b445274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadae9d6-f1aa-4740-af9a-5c9f511543ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
